#!/bin/bash

# Terminal utils

# Launch a full stack CMS glidein on a set of THETA nodes
# Gathering parameters for the request
THETA_USER=macosta
NODE_CNT=1
QUEUE=debug-cache-quad
TIME="60"
JOB_ID=${RANDOM}
ALLOCATION=HEPCloud-FNAL
verbose='false'

while getopts 'u:n:q:t:v:j:f:' flag; do
  case "${flag}" in
    u) THETA_USER="${OPTARG}" ;;
    n) NODE_CNT="${OPTARG}" ;;
    q) QUEUE="${OPTARG}" ;;
    t) TIME="${OPTARG}" ;;
    j) JOB_ID="${OPTARG}" ;;
    f) SCHEDD_FILE="${OPTARG}" ;;
    a) ALLOCATION="${OPTARG}" ;;
    v) verbose='true' ;;
    *) echo "Usage: $0 -u [<THETA user>] -n [<node cnt>] [<THETA base directory>]" 1>&2 ; exit 1
       ;;
  esac
done

SLOT_PREFIX="cobalt-cms-${JOB_ID}"
GLIDEIN_NAME="cobalt-cms-${JOB_ID}@theta.alcf.anl.gov"
THETA_BASE_DIR="/projects/${ALLOCATION}/job_area/${SLOT_PREFIX}"
SOURCE="$(dirname "${PWD}")"
EDGE_BASE_DIR=`pwd`

echo "====== Submitting a Lumberjack cobalt job from ${HOSTNAME} under local Linux user $(whoami)"
LNS=$(qstat -u ${THETA_USER} | wc -l)
if [ $LNS -gt 2 ]
then
  echo "WARN: There are COBALT jobs in the queue"
  qstat -u ${THETA_USER}
fi

echo ====== Creating base directory on shared storage
mkdir ${THETA_BASE_DIR}
echo INFO: Using directory $THETA_BASE_DIR

# Set up local Condor installation
echo ====== Writing base files
echo Copy the "skeleton" folder as-is
cp -dR skeleton/* $THETA_BASE_DIR/
echo Put the job_queue.log file in place
cp -dR ${SCHEDD_FILE} $THETA_BASE_DIR/spool/job_queue.log
echo Generate and make sure permissions are well set for the pool_password
openssl rand -hex 32 > $THETA_BASE_DIR/secrets/pool_password
chmod 400 $THETA_BASE_DIR/secrets/pool_password
echo "Add custom names to our daemons"
cat >$THETA_BASE_DIR/condor/config.d/97-personal2.conf <<EOF
# Run-time settings for this personal condor setup
#new startd name
MASTER_NAME = master_${GLIDEIN_NAME}
COLLECTOR_NAME = coll_${GLIDEIN_NAME} 
SCHEDD_NAME = sched_${GLIDEIN_NAME}
STARTD_NAME = startd_${GLIDEIN_NAME}
EOF

# write theta files
echo ====== Writing files for job submission
cat > ${THETA_BASE_DIR}/job.cobalt <<EOF
#!/bin/bash

# number of nodes
#COBALT -n ${NODE_CNT}
# wall time request, this is 30min
#COBALT -t ${TIME}
# one of the two debug queues, only difference is KNL cache settings
#COBALT -q ${QUEUE}
# project, this should work for the ALCC allocation
#COBALT -A ${ALLOCATION}

export MY_JOBID=${JOB_ID}
# MPI launcher, 1 node, 1 MPI rank per node
# basically starts mycommand on both nodes in the batch job
EOF

# Next
# Submitting the "head" job with: Master, Collector, Negotiator, Schedd and Startds (in case I'm running on a single node)
echo "aprun -n 1 -N 1 -d 1 -j 1 --cc none --env SLOT_PREFIX=${SLOT_PREFIX} --env COBALT_NODEID=${i} ./minicondor_lumberjack_start.sh -r CentralManager &" >> ${THETA_BASE_DIR}/job.cobalt
# Submitting "worker" jobs with: Master, Startd
for ((i=1;i<=${NODE_CNT};i++)); do
    echo "aprun -n 1 -N 1 -d 1 -j 1 --cc none --env SLOT_PREFIX=${SLOT_PREFIX} --env COBALT_NODEID=${i} ./minicondor_lumberjack_start.sh -r Execute &" >> ${THETA_BASE_DIR}/job.cobalt
    echo "sleep 1" >> ${THETA_BASE_DIR}/job.cobalt
done

echo "wait" >> ${THETA_BASE_DIR}/job.cobalt

chmod a+rx ${THETA_BASE_DIR}/job.cobalt

echo INFO: Files written

echo INFO: Submitting COBALT job 

# Submit cobalt job
cd ${THETA_BASE_DIR}; qsub -A ${ALLOCATION} -q ${QUEUE} -t ${TIME} -n ${NODE_CNT} --jobname=${SLOT_PREFIX} --attr ssds=required job.cobalt
echo INFO: Done, check your job and files at ${THETA_BASE_DIR}
