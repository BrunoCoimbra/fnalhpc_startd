#!/bin/bash

# Terminal utils
BL="\033[1;34m"
YL="\033[1;33m"
WHT="\033[1;97m"
CY="\033[1;36m"
MGT="\033[1;35m"
GR="\033[1;32m"
RD="\033[1;31m"
NO_COLOR="\033[0m"

# Launch a full stack CMS glidein on a set of THETA nodes
# Gathering parameters for the request
THETA_USER=macosta
NODE_CNT=1
QUEUE=debug-cache-quad
TIME="60"
JOB_ID=${RANDOM}
ALLOCATION=HEPCloud-FNAL
verbose='false'

while getopts 'u:n:q:t:v:j:f:h' flag; do
  case "${flag}" in
    u) THETA_USER="${OPTARG}" ;;
    n) NODE_CNT="${OPTARG}" ;;
    q) QUEUE="${OPTARG}" ;;
    t) TIME="${OPTARG}" ;;
    j) JOB_ID="${OPTARG}" ;;
    f) SCHEDD_FILE="${OPTARG}" ;;
    a) ALLOCATION="${OPTARG}" ;;
    v) verbose='true' ;;
    h) echo "Usage: $0"
       echo "Optional: -u [<THETA user>] -n [<Node count>] -q [<THETA queue>] -t [<Node time>] -a [<THETA allocation]>"
       echo "Required: -f [<SCHEDD job queue file]" 1>&2 ; exit 1
       ;;
  esac
done

if [ -z "${SCHEDD_FILE}" ]
then
  echo -e "${RD}# ERROR: A required parameter '-f [<SCHEDD job queue file]' was not detected"
  echo -e "${RD}# I need a lumberjack-exported job_queue.log to work properly"
  echo -e "# For insructions about the experimental export process, go to: https://github.com/HEPCloud/fnalhpc_startd/tree/master/lumberjack"
exit 1
fi 

export SLOT_PREFIX="cobalt-cms-${JOB_ID}"
export GLIDEIN_NAME="cobalt-cms-${JOB_ID}@theta.alcf.anl.gov"
export THETA_BASE_DIR="/projects/${ALLOCATION}/job_area/${SLOT_PREFIX}"

echo "====== Submitting a Lumberjack cobalt job from ${HOSTNAME}"
echo "Local Linux user: $(whoami)"
LNS=$(qstat -u ${THETA_USER} | wc -l)
if [ $LNS -gt 2 ]
then
  echo "WARN: There are COBALT jobs in the queue"
  qstat -u ${THETA_USER}
fi

echo ""
echo ====== Creating base directory on shared storage
mkdir ${THETA_BASE_DIR}
echo Using directory $THETA_BASE_DIR

# Set up local Condor installation
echo ""
echo ====== Writing base files
echo Copy the "skeleton" folder as-is
cp -dR skeleton/* $THETA_BASE_DIR/
cp -dR sawmill_payload_start.sh $THETA_BASE_DIR/sawmill_payload_start.sh
echo Put the job_queue.log file in place
export JOB_QUEUE=$THETA_BASE_DIR/local_dir/lib/condor/spool/job_queue.log
cp -dR ${SCHEDD_FILE} ${JOB_QUEUE}

echo Generate and make sure permissions are well set for the pool_password
openssl rand -hex 32 > $THETA_BASE_DIR/secrets/pool_password
chmod 400 $THETA_BASE_DIR/secrets/pool_password
echo "Add custom names to our daemons"
cat >$THETA_BASE_DIR/condor/config.d/97-personal2.conf <<EOF
# Run-time settings for this personal condor setup
#new startd name
MASTER_NAME = master_${GLIDEIN_NAME}
COLLECTOR_NAME = coll_${GLIDEIN_NAME} 
SCHEDD_NAME = sched_${GLIDEIN_NAME}
STARTD_NAME = startd_${GLIDEIN_NAME}
EOF

echo ""
echo "====== Analyzing job_queue.log for directories needed by my jobs"
echo ""

source stage_lumberjack_files

# Write theta files
echo ====== Writing files for job submission
cat > ${THETA_BASE_DIR}/job.cobalt <<EOF
#!/bin/bash

# number of nodes
#COBALT -n ${NODE_CNT}
# wall time request, this is 30min
#COBALT -t ${TIME}
# one of the two debug queues, only difference is KNL cache settings
#COBALT -q ${QUEUE}
# project, this should work for the ALCC allocation
#COBALT -A ${ALLOCATION}

export MY_JOBID=${JOB_ID}
# MPI launcher, 1 node, 1 MPI rank per node
# basically starts mycommand on both nodes in the batch job
EOF

# Next
# Submitting the "head" job with: Master, Collector, Negotiator, Schedd and Startds (in case I'm running on a single node)
echo "aprun -n 1 -N 1 -d 1 -j 1 --cc none --env SLOT_PREFIX=${SLOT_PREFIX} --env COBALT_NODEID=1 ./sawmill_payload_start.sh -r CentralManager &" >> ${THETA_BASE_DIR}/job.cobalt
# Submitting "worker" jobs with: Master, Startd
for ((i=2;i<=${NODE_CNT};i++)); do
    echo "aprun -n 1 -N 1 -d 1 -j 1 --cc none --env SLOT_PREFIX=${SLOT_PREFIX} --env COBALT_NODEID=${i} ./sawmill_payload_start.sh -r Execute &" >> ${THETA_BASE_DIR}/job.cobalt
    echo "sleep 1" >> ${THETA_BASE_DIR}/job.cobalt
done

echo "wait" >> ${THETA_BASE_DIR}/job.cobalt

chmod a+rx ${THETA_BASE_DIR}/job.cobalt

echo Files written
echo Fixing permissions on directories to bind
chmod -R 777 $THETA_BASE_DIR/local_dir
echo Submitting COBALT job 

# Submit cobalt job
cd ${THETA_BASE_DIR}; qsub -A ${ALLOCATION} -q ${QUEUE} -t ${TIME} -n ${NODE_CNT} --jobname=${SLOT_PREFIX} --attr ssds=required:enable_ssh=1 job.cobalt
echo ""
echo Done.. Check your job and files at ${THETA_BASE_DIR}
